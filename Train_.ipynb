{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQZ54ABTh4EImHEVx0Yi6o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LevonaHayoun/3d_Unet_Segmentation/blob/main/Train_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6oxYVyo0Hyx"
      },
      "outputs": [],
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel, tqdm]\"\n",
        "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
        " %matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tempfile\n",
        "from monai.data import Dataset, DataLoader, decollate_batch\n",
        "from monai.transforms.compose import Compose\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from monai.handlers.utils import from_engine\n",
        "from monai.losses import DiceLoss\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.networks.nets import SegResNet\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    Activationsd,\n",
        "    AsDiscrete,\n",
        "    AsDiscreted,\n",
        "    Compose,\n",
        "    Invertd,\n",
        "    LoadImaged,\n",
        "    MapTransform,\n",
        "    NormalizeIntensityd,\n",
        "    Orientationd,\n",
        "    Resized,\n",
        "    RandFlipd,\n",
        "    RandScaleIntensityd,\n",
        "    RandShiftIntensityd,\n",
        "    RandSpatialCropd,\n",
        "    Spacingd,\n",
        "    EnsureTyped,\n",
        "    EnsureChannelFirstd,\n",
        ")\n",
        "from monai.utils import first,set_determinism\n",
        "\n",
        "import torch\n",
        "\n",
        "import glob\n",
        "\n",
        "\n",
        "set_determinism(seed=0)"
      ],
      "metadata": {
        "id": "GQAIXMYV1GeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convert to Binary classes"
      ],
      "metadata": {
        "id": "aSkifd9M1mWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvertToBinaryClasses(MapTransform):\n",
        "\n",
        "\n",
        "\n",
        "    def __call__(self, data):\n",
        "        d = dict(data)\n",
        "        for key in self.keys:\n",
        "            result=[]\n",
        "            result.append(torch.logical_or(torch.logical_or(d[key] == 2, d[key] == 3), d[key]== 255))\n",
        "\n",
        "            d[key] = torch.stack(result, axis=0).float()\n",
        "\n",
        "        return d"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3Z7uO_3q1fk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup transforms for training and validation"
      ],
      "metadata": {
        "id": "pswma9CV13iK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = Compose([\n",
        "    LoadImaged(keys=[\"image\", \"label\"]),\n",
        "    EnsureChannelFirstd(keys=\"image\"),\n",
        "    EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "    ConvertToBinaryClasses(keys=\"label\"),\n",
        "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "    #Spacingd(keys=[\"image\", \"label\"], pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "    RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=[224, 224, 144], random_size=False),\n",
        "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
        "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
        "    RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
        "    NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
        "    RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
        "    RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
        "])\n",
        "\n",
        "\n",
        "val_transform = Compose([\n",
        "    LoadImaged(keys=[\"image\", \"label\"]),\n",
        "    EnsureChannelFirstd(keys=\"image\"),\n",
        "    EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "    ConvertToBinaryClasses(keys=\"label\"),\n",
        "    Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "    #Spacingd(keys=[\"image\", \"label\"], pixdim=(1.0, 1.0, 1.0), mode=(\"bilinear\", \"nearest\")),\n",
        "    NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
        "])\n"
      ],
      "metadata": {
        "id": "Cm-jO6Vh1ydm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing data"
      ],
      "metadata": {
        "id": "rL7FhLbn19Kp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir='/workspace/Project/train'\n",
        "train_images = sorted(glob.glob(os.path.join(data_dir, \"imagesTr\", \"*.nii.gz\")))\n",
        "train_labels = sorted(glob.glob(os.path.join(data_dir, \"labelsTr\", \"*.nii.gz\")))\n",
        "train_dicts = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_images, train_labels)]\n",
        "train_files = train_dicts\n",
        "\n",
        "\n",
        "data_dir='/workspace/Project/val'\n",
        "val_images = sorted(glob.glob(os.path.join(data_dir, \"imagesTr\", \"*.nii.gz\")))\n",
        "val_labels = sorted(glob.glob(os.path.join(data_dir, \"labelsTr\", \"*.nii.gz\")))\n",
        "val_dicts = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(val_images, val_labels)]\n",
        "val_files = val_dicts\n",
        "\n",
        "\n",
        "train_files"
      ],
      "metadata": {
        "id": "mpam2p0F1_jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Applying transform on data"
      ],
      "metadata": {
        "id": "V-vknPqq2KqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = Dataset(data=train_files, transform=train_transform)\n",
        "train_loader = DataLoader(train_ds, batch_size=1)\n",
        "\n",
        "\n",
        "val_ds = Dataset(data=val_files, transform=val_transform)\n",
        "val_loader = DataLoader(val_ds, batch_size=1)"
      ],
      "metadata": {
        "id": "9zwO65-U2L37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One image for visualization"
      ],
      "metadata": {
        "id": "30TqCv2j2OcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_ds))\n",
        "val_data_example = train_ds[0]\n",
        "\n",
        "print(f\"image shape: {val_data_example['image'].shape}\")\n",
        "plt.figure(\"image\", (24, 6))\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.title(f\"image channel {1}\")\n",
        "plt.imshow(val_data_example[\"image\"][0, :, :,80].detach().cpu(), cmap=\"gray\")\n",
        "plt.show()\n",
        "\n",
        "# also visualize the 3 channels label corresponding to this image\n",
        "print(f\"label shape: {val_data_example['label'].shape}\")\n",
        "plt.figure(\"label\", (18, 6))\n",
        "plt.subplot(1, 3,1)\n",
        "plt.title(f\"label channel {1}\")\n",
        "plt.imshow(val_data_example[\"label\"][0, :, :,80].detach().cpu())\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_QRVz1Le2RLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set up for training\n",
        "\n"
      ],
      "metadata": {
        "id": "nawNJuEs2WRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Model, Loss, Optimizer\n",
        "\n",
        "max_epochs = 300\n",
        "val_interval = 1\n",
        "VAL_AMP = True\n",
        "\n",
        "# standard PyTorch program style: create SegResNet, DiceLoss and Adam optimizer\n",
        "device = torch.device(\"cuda:0\")\n",
        "model = SegResNet(\n",
        "    blocks_down=[1, 2, 2, 4],\n",
        "    blocks_up=[1, 1, 1],\n",
        "    init_filters=16,\n",
        "    in_channels=1,\n",
        "    out_channels=1,\n",
        "    dropout_prob=0.2,\n",
        ").to(device)\n",
        "loss_function = DiceLoss(smooth_nr=0, smooth_dr=1e-5, squared_pred=True, to_onehot_y=False, sigmoid=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-4, weight_decay=1e-5)\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)\n",
        "\n",
        "dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
        "dice_metric_batch = DiceMetric(include_background=True, reduction=\"mean_batch\")\n",
        "\n",
        "post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
        "\n",
        "\n",
        "# define inference method\n",
        "def inference(input):\n",
        "    def _compute(input):\n",
        "        return sliding_window_inference(\n",
        "            inputs=input,\n",
        "            roi_size=(240, 240, 160),\n",
        "            sw_batch_size=1,\n",
        "            predictor=model,\n",
        "            overlap=0.5,\n",
        "        )\n",
        "\n",
        "    if VAL_AMP:\n",
        "        with torch.cuda.amp.autocast():\n",
        "            return _compute(input)\n",
        "    else:\n",
        "        return _compute(input)\n",
        "\n",
        "\n",
        "# use amp to accelerate training\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "# enable cuDNN benchmark\n",
        "torch.backends.cudnn.benchmark = True"
      ],
      "metadata": {
        "id": "uzJ9g0Co2f5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Execute a typical PyTorch training process"
      ],
      "metadata": {
        "id": "Lnl1QfTc2mmB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "best_metrics_epochs_and_time = [[], [], []]\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "metric_values_wt = []\n",
        "\n",
        "total_start = time.time()\n",
        "for epoch in range(max_epochs):\n",
        "    epoch_start = time.time()\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in train_loader:\n",
        "        step_start = time.time()\n",
        "        step += 1\n",
        "        inputs, labels = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n",
        "        print(f\"shape of x: {inputs.shape}\")\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        epoch_loss += loss.item()\n",
        "        print(\n",
        "            f\"{step}/{len(train_ds) // train_loader.batch_size}\"\n",
        "            f\", train_loss: {loss.item():.4f}\"\n",
        "            f\", step time: {(time.time() - step_start):.4f}\"\n",
        "        )\n",
        "    lr_scheduler.step()\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for val_data in val_loader:\n",
        "                val_inputs, val_labels = val_data[\"image\"].to(device), val_data[\"label\"].to(device)\n",
        "                val_outputs = inference(val_inputs)\n",
        "                val_outputs = [post_trans(i) for i in decollate_batch(val_outputs)]\n",
        "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "                dice_metric_batch(y_pred=val_outputs, y=val_labels)\n",
        "\n",
        "            metric = dice_metric.aggregate().item()\n",
        "            metric_values.append(metric)\n",
        "            metric_batch = dice_metric_batch.aggregate()\n",
        "            metric_wt = metric_batch[0].item()\n",
        "            metric_values_wt.append(metric_wt)\n",
        "            dice_metric.reset()\n",
        "            dice_metric_batch.reset()\n",
        "\n",
        "            if metric > best_metric:\n",
        "                best_metric = metric\n",
        "                best_metric_epoch = epoch + 1\n",
        "                best_metrics_epochs_and_time[0].append(best_metric)\n",
        "                best_metrics_epochs_and_time[1].append(best_metric_epoch)\n",
        "                best_metrics_epochs_and_time[2].append(time.time() - total_start)\n",
        "                torch.save(\n",
        "                    model.state_dict(),\n",
        "                    os.path.join(data_dir, \"best_metric_model.pth\"),\n",
        "                )\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
        "                f\"\\nbest mean dice: {best_metric:.4f}\"\n",
        "                f\" at epoch: {best_metric_epoch}\"\n",
        "            )\n",
        "    print(f\"time consuming of epoch {epoch + 1} is: {(time.time() - epoch_start):.4f}\")\n",
        "total_time = time.time() - total_start\n",
        "\n",
        "print(f\"train completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}, total time: {total_time}.\")"
      ],
      "metadata": {
        "id": "EH0R6b932o1R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}